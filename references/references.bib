
@article{beaulieu-jonesReproducibilityComputationalWorkflows2017,
  title = {Reproducibility of Computational Workflows Is Automated Using Continuous Analysis},
  author = {{Beaulieu-Jones}, Brett K and Greene, Casey S},
  year = {2017},
  pages = {342},
  issn = {1087-0156},
  abstract = {Replication, validation and extension of experiments are crucial for scientific progress. Computational experiments are scriptable and should be easy to reproduce. However, computational analyses are designed and run in a specific computing environment, which may be difficult or impossible to match using written instructions. We report the development of continuous analysis, a workflow that enables reproducible computational analyses. Continuous analysis combines Docker, a container technology akin to virtual machines, with continuous integration, a software development technique, to automatically rerun a computational analysis whenever updates or improvements are made to source code or data. This enables researchers to reproduce results without contacting the study authors. Continuous analysis allows reviewers, editors or readers to verify reproducibility without manually downloading and rerunning code and can provide an audit trail for analyses of data that cannot be shared.},
  annotation = {mlzsync1:0055\{"extrafields":\{"publisher":"Nature Publishing Group"\}\}tex.ids: beaulieu-jonesReproducibilityComputationalWorkflows2017a, beaulieu-jonesReproducibilityComputationalWorkflows2017b},
  file = {/Users/awwillc/Zotero/storage/8FC6PNTZ/Beaulieu-Jones and Greene - 2017 - Reproducibility of computational workflows is auto.pdf;/Users/awwillc/Zotero/storage/NPIE3MTS/Beaulieu-Jones and Greene - 2017 - Reproducibility of computational workflows is auto.pdf;/Users/awwillc/Zotero/storage/5QD8UBBF/nbt.html},
  journal = {Nature Biotechnology},
  keywords = {*Machine Learning,*Software,*User-Computer Interface,*Workflow,Company business management,Computational Biology/*methods,Gene Expression Profiling/*methods,Reproducibility of Results,Science publishing -- Management,Sensitivity and Specificity},
  number = {4},
  pmcid = {PMC6103790},
  pmid = {28288103}
}

@inproceedings{debayserResearchOpsCaseDevOps2015,
  title = {{{ResearchOps}}: {{The}} Case for {{DevOps}} in Scientific Applications},
  shorttitle = {{{ResearchOps}}},
  booktitle = {2015 {{IFIP}}/{{IEEE International Symposium}} on {{Integrated Network Management}} ({{IM}})},
  author = {{de Bayser}, Maximilien and Azevedo, Leonardo G. and Cerqueira, Renato},
  year = {2015},
  month = may,
  pages = {1398--1404},
  publisher = {{IEEE}},
  address = {{Ottawa, ON, Canada}},
  doi = {10/ghkb9s},
  abstract = {DevOps (a portmanteau of ``development'' and ``operations'') is a software development method that extends the agile philosophy to rapidly produce software products and services and to improve operations performance and quality assurance. It was born to accelerate the delivery of web-based systems and quickly bring new value to users. Many web-based systems evolve according to usage trends without a clear longterm goal. Before the widespread use of web services, most software with a clear goal were delivered as packages that users installed on their own system. New versions were delivered with a much lower frequency, with periods in between versions ranging from months to years. Development cycles were divided into large design, coding and testing phases culminating in the release of a new stable version. In software development in the context of applied science, even when the goal is clear, the process to attain it is not. Hence, working releases that capture the current software state must be released frequently in order to reduce the risks for all stakeholders and to make it possible to assess the current state of a project and steer it in the right direction. This paper explores the usefulness of DevOps concepts to improve the development of software that supports scientific projects. We establish the similarities and differences between scientific projects and web applications development, and discuss where the related methodologies need to be extended. Unique challenges are discussed herewith developed solutions, and still open questions. Lessons learned are highlighted as best practices to be followed in research projects. This discussion is rooted in our experience in real-life projects at the IBM Research Brazil Lab, which just as well apply to other research institutions.},
  file = {/Users/awwillc/Zotero/storage/C6GZ6738/de Bayser et al. - 2015 - ResearchOps The case for DevOps in scientific app.pdf},
  isbn = {978-1-4799-8241-7},
  language = {en}
}

@book{diazDevOpsPracticePreliminary2019,
  title = {{{DevOps}} in {{Practice}} -- {{A}} Preliminary {{Analysis}} of Two {{Multinational Companies}}},
  author = {D{\'i}az, Jessica and {P{\'e}rez-Mart{\'i}nez}, Jorge and Yague, Agustin and Villegas, Andrea and Antona, Antonio},
  year = {2019},
  month = oct,
  abstract = {DevOps is a cultural movement that aims the collaboration of all the stakeholders involved in the development, deployment and operation of soft-ware to deliver a quality product or service in the shortest possible time. DevOps is relatively recent, and companies have developed their DevOps prac-tices largely from scratch. Our research aims to conduct an analysis on practic-ing DevOps in +20 software-intensive companies to provide patterns of DevOps practices and identify their benefits and barriers. This paper presents the preliminary analysis of an exploratory case study based on the interviews to relevant stakeholders of two (multinational) companies. The results show the benefits (software delivery performance) and barriers that these companies are dealing with, as well as DevOps team topology they approached during their DevOps transformation. This study aims to help practitioners and researchers to better understand DevOps transformations and the contexts where the practices worked. This, hopefully, will contribute to strengthening the evidence regarding DevOps and supporting practitioners in making better informed decisions about the return of investment when adopting DevOps.},
  file = {/Users/awwillc/Zotero/storage/R9BSPX7X/Díaz et al. - 2019 - DevOps in Practice -- A preliminary Analysis of tw.pdf}
}

@article{Hatton2019137,
  title = {Computational Reproducibility: {{The}} Elephant in the Room},
  author = {Hatton, L. and Van Genuchten, M.},
  year = {2019},
  volume = {36},
  pages = {137--144},
  publisher = {{IEEE Computer Society}},
  issn = {07407459},
  doi = {10/ggkvtr},
  abbrev_source_title = {IEEE Software},
  affiliation = {Kingston University, London, United Kingdom; VitalHealth Software, United Kingdom},
  art_number = {8648256},
  coden = {IESOE},
  document_type = {Article},
  file = {/Users/awwillc/Zotero/storage/I78Y7EZY/Hatton and Van Genuchten - 2019 - Computational reproducibility The elephant in the.pdf},
  journal = {IEEE Software},
  language = {English},
  number = {2},
  source = {Scopus}
}

@article{hocquetEpistemicIssuesComputational2021,
  title = {Epistemic Issues in Computational Reproducibility: Software as the Elephant in the Room},
  author = {Hocquet, Alexandre and Wieber, Fr{\'e}d{\'e}ric},
  year = {2021},
  volume = {11},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  issn = {1879-4912},
  doi = {10/gkm94m},
  abstract = {Computational reproducibility (i.e. issues of reproducibility stemming from the computer as a scientific tool) possesses its own dynamics and narratives of crisis. Alongside the difficulties of computing as an ubiquitous yet complex scientific activity, computational reproducibility suffers from a naive expectancy of total reproducibility and a moral imperative to embrace the principles of free software as a non-negotiable epistemic virtue. We argue that the epistemic issues at stake in actual practices of computational reproducibility are best unveiled by focusing on software as a pivotal concept, one that is surprisingly often overlooked in accounts of reproducibility issues. Software is not only about designing and coding but also about maintaining, supporting, distributing, licensing, and governance; it is not only about developers but also about users. We focus on openness debates among computational chemists involved in molecular modeling software packages as empirical grounding for our argument. We then identify and analyse four epistemic characteristics (transparency, consistency, sustainability and inclusivity) as key to the role of software in computational reproducibility.},
  journal = {European Journal for Philosophy of Science},
  keywords = {Computational chemistry,Computational reproducibility,Consistency,Inclusivity,Software,Sustainability,Transparency},
  number = {2}
}

@article{ISI:000454682100001,
  title = {Towards Computational Reproducibility: Researcher Perspectives on the Use and Sharing of Software},
  author = {AlNoamany, Yasmin and Borghi, John A.},
  year = {2018},
  month = sep,
  publisher = {{PEERJ INC}},
  address = {{341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND}},
  issn = {2376-5992},
  doi = {10/ghkb9j},
  abstract = {Research software, which includes both source code and executables used as part of the research process, presents a significant challenge for efforts aimed at ensuring reproducibility. In order to inform such efforts, we conducted a survey to better understand the characteristics of research software as well as how it is created, used, and shared by researchers. Based on the responses of 215 participants, representing a range of research disciplines, we found that researchers create, use, and share software in a wide variety of forms for a wide variety of purposes, including data collection, data analysis, data visualization, data cleaning and organization, and automation. More participants indicated that they use open source software than commercial software. While a relatively small number of programming languages (e.g., Python, R, JavaScript, C++, MATLAB) are used by a large number, there is a long tail of languages used by relatively few. Between-group comparisons revealed that significantly more participants from computer science write source code and create executables than participants from other disciplines. Differences between researchers from computer science and other disciplines related to the knowledge of best practices of software creation and sharing were not statistically significant. While many participants indicated that they draw a distinction between the sharing and preservation of software, related practices and perceptions were often not aligned with those of the broader scholarly communications community.},
  affiliation = {AlNoamany, Y (Corresponding Author), Univ Calif Berkeley, Berkeley, CA 94720 USA. AlNoamany, Yasmin, Univ Calif Berkeley, Berkeley, CA 94720 USA. Borghi, John A., Calif Digital Lib, Oakland, CA USA.},
  article-number = {e163},
  author-email = {yasminal@berkeley.edu},
  cited-references = {AlNoamany Y, 2018, DATA RE PERSPECTIVES, DOI [10.6078/D1HM2W, DOI 10.6078/D1HM2W]. AlNoamany Y, 2018, ZENODO, DOI [10.5281/zenodo.1195605, DOI 10.5281/ZENODO.1195605]. Barnes N, 2010, NATURE, V467, P753, DOI 10.1038/467753a. Boettiger Carl, 2015, ACM SIGOPS Operating Systems Review, V49, P71. Borgman CL, 2012, COMPUT SUPP COOP W J, V21, P485, DOI 10.1007/s10606-012-9169-z. Chassanoff A, 2018, OSF PREPRINTS, DOI [10.31219/osf.io/fb5s8, DOI 10.31219/OSF.IO/FB5S8]. Chirigati F., 2013, P 5 USENIX C THEOR P, P1. Cochrane E, 2018, J DIGITAL MEDIA MANA, V6, P255. Crouch S, 2013, COMPUT SCI ENG, V15, P74, DOI 10.1109/MCSE.2013.133. Eglen SJ, 2017, NAT NEUROSCI, V20, P770, DOI 10.1038/nn.4550. Fecher B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118053. Goble C, 2014, IEEE INTERNET COMPUT, V18, P4, DOI 10.1109/MIC.2014.88. Goodman SN, 2016, SCI TRANSL MED, V8, DOI 10.1126/scitranslmed.aaf5027. Hafer L, 2009, COMMUN ACM, V52, P126, DOI 10.1145/1610252.1610285. Hannay JE, 2009, 2009 ICSE WORKSHOP ON SOFTWARE ENGINEERING FOR COMPUTATIONAL SCIENCE AND ENGINEERING, P1, DOI 10.1109/SECSE.2009.5069155. Herbsleb J.D., 2011, P ACM 2011 C COMP SU, DOI [10.1145/1958824.1958904, DOI 10.1145/1958824.1958904]. Hey T, 2009, 4 PARADIGM DATA INTE. Hong NC, 2011, DIGITAL PRESERVATION. Hong NC, 2014, DEALING SOFTWARE RES, DOI [10.6084/m9.figshare.1150299, DOI 10.6084/M9.FIGSHARE.1150299]. Howison J, 2013, P 2013 C COMP SUPP C, P459, DOI DOI 10.1145/2441776.2441828. Howison J, 2015, TECHNICAL REPORT. Howison J, 2016, J ASSOC INF SCI TECH, V67, P2137, DOI 10.1002/asi.23538. Hucka M, 2018, J SYST SOFTWARE, V141, P171, DOI 10.1016/j.jss.2018.03.047. Ince DC, 2012, NATURE, V482, P485, DOI 10.1038/nature10836. Jimenez Rafael C, 2017, F1000Res, V6, DOI 10.12688/f1000research.11407.1. Joppa LN, 2013, SCIENCE, V340, P814, DOI 10.1126/science.1231535. Katz DS, 2013, J OPEN RES SOFTWARE, V6, P10, DOI [10.5334/jors.184, DOI 10.5334/JORS.184]. Kim Y, 2016, J ASSOC INF SCI TECH, V67, P776, DOI 10.1002/asi.23424. Kissel R, 2011, 7298 NIST IR, V7298. Kluyver T, 2016, POSITIONING AND POWER IN ACADEMIC PUBLISHING: PLAYERS, AGENTS AND AGENDAS, P87, DOI 10.3233/978-1-61499-649-1-87. Kratz JE, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0117619. Marwick B, 2017, J ARCHAEOL METHOD TH, V24, P424, DOI 10.1007/s10816-015-9272-9. McCarthy DJ, 2014, GENOME MED, V6, DOI 10.1186/gm543. Meyerson J, 2017, D LIB MAGAZINE, V23, DOI [10.1045/MAY2017.meyerson, DOI 10.1045/MAY2017.MEYERSON]. Monteith JY, 2014, P 2014 EUR C SOFTW A, DOI 10.1145/2642803.2642812. Morin A, 2012, SCIENCE, V336, P159, DOI 10.1126/science.1218263. Morin A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002598. Munafo MR, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-016-0021. National Institutes of Health (NIH), 2016, STRAT NIH DAT MAN SH. Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374. Nosek BA, 2012, PERSPECT PSYCHOL SCI, V7, P615, DOI 10.1177/1745691612459058. Pan XL, 2016, SCIENTOMETRICS, V109, P1593, DOI 10.1007/s11192-016-2138-4. Perez F, 2007, COMPUT SCI ENG, V9, P21, DOI 10.1109/MCSE.2007.53. Piccolo SR, 2016, GIGASCIENCE, V5, DOI 10.1186/s13742-016-0135-4. Prabhu P, 2011, STATE PRACTICE REPOR, P19, DOI [10.1145/2063348.2063374, DOI 10.1145/2063348.2063374]. Prlic A, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002802. Ram K, 2017, SI2 S2I2 CONCEPTUALI. Rios Fernando, 2016, D-Lib Magazine, V22, DOI 10.1045/july2016-rios. Rios F, 2017, OPEN SCI FRAMEWORK, DOI [10.17605/OSF.IO/D4KEF, DOI 10.17605/OSF.IO/D4KEF]. Sadowski C, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P191, DOI 10.1145/2786805.2786855. Sandve GK, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003285. Sayre F, 2018, COLL RES LIBR, V79, P2, DOI 10.5860/crl.79.1.2. Smith AM, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.86. StackOverflow, 2017, DEV SURV RES 2017. Steeves V, 2017, COLLABORATIVE LIB, V9, P80. Stodden V., 2014, IMPLEMENTING REPROD. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Stodden V, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067111. Stodden V, 2009, COMPUT SCI ENG, V11, P35, DOI 10.1109/MCSE.2009.19. Teal T. K., 2015, INT J DIGIT CURATION, V10, P343, DOI [10.2218/ijdc.v10i1.351., DOI 10.2218/IJDC.V10I1.351, 10.2218/ijdc.v10i1.351]. Tenopir C, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021101. Thain D, 2015, P 12 INT C DIG PRES, DOI [10.7274/R0CZ353M, DOI 10.7274/R0CZ353M]. Vandewalle P, 2012, COMPUT SCI ENG, V14, P42, DOI 10.1109/MCSE.2012.63. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18. Wilson G., 2017, PLOS COMPUT BIOL, V13, P1, DOI [10.1371/journal.pcbi.1005510, DOI 10.1371/J0URNAL.PCBI.1005510]. Wilson G, 2006, COMPUT SCI ENG, V8, P66, DOI 10.1109/MCSE.2006.122.},
  da = {2021-06-23},
  doc-delivery-number = {HG1AR},
  file = {/Users/awwillc/Zotero/storage/4E7UZK2C/AlNoamany and Borghi - 2018 - Towards computational reproducibility researcher .pdf},
  funding-acknowledgement = {Alfred P. Sloan FoundationAlfred P. Sloan Foundation [G-2015-14112, G-2014-13746]; National Science Foundation NSF (ACI)National Science Foundation (NSF) [1349002]; Berkeley Research Impact Initiative (BRII) - UC Berkeley Library},
  funding-text = {This work is supported in part by Alfred P. Sloan Foundation (\#G-2015-14112 and \#G-2014-13746) and the National Science Foundation NSF (ACI \#1349002). This publication was made possible in part by support from the Berkeley Research Impact Initiative (BRII) sponsored by the UC Berkeley Library. There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.},
  journal = {PEERJ COMPUTER SCIENCE},
  journal-iso = {PeerJ Comput. Sci.},
  keywords = {Software sustainability; Reproducibility; Research software; Code; Finding software; Sharing software},
  keywords-plus = {COMPUTER CODE; SCIENTISTS; SCIENCE; IMPACT},
  language = {English},
  number-of-cited-references = {66},
  oa = {DOAJ Gold, Green Published},
  research-areas = {Computer Science},
  times-cited = {9},
  type = {Article},
  unique-id = {ISI:000454682100001},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory \& Methods}
}

@article{ISI:000473184100005,
  title = {Lifecycle Support for Scientific Investigations: {{Integrating}} Data, Computing, and Workflows},
  author = {Catlin, Ann Christine and HewaNadungodage, Chandima and Bejarano, Andres},
  year = {2019},
  month = jul,
  volume = {21},
  pages = {49--61},
  publisher = {{IEEE COMPUTER SOC}},
  address = {{10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA}},
  issn = {1521-9615},
  doi = {10/gjt725},
  abstract = {Scientific workflows have emerged as a model for representing the complex processes carried out by scientists throughout their investigations, encompassing research activities corresponding to data collection, data flow, computation, output analysis, and all the ways these are used together to produce results. Existing infrastructures support elements of the workflow, such as data repositories or computing services, but these are not integrated as interactive environments that provide full investigation lifecycle support. The digital environment for enabling data-driven sciences (DEEDS) project brought together domain scientists and computer scientists to create a platformthat provides interactive end-to-end support for diverse scientific workflows. Key among requirements were preservation, provenance, coupling of data and computing, results traceability, collaborative sharing, exploration, and publication of the full products of research work. This paper highlights use cases that contributed to DEEDS development and concludes with lessons learned from a process that joined experiences and perspectives from diverse science domains.},
  affiliation = {Catlin, AC (Corresponding Author), Purdue Univ, Rosen Ctr Adv Comp, W Lafayette, IN 47907 USA. Catlin, Ann Christine; HewaNadungodage, Chandima; Bejarano, Andres, Purdue Univ, Rosen Ctr Adv Comp, W Lafayette, IN 47907 USA. Bejarano, Andres, Purdue Univ, Comp Sci, W Lafayette, IN 47907 USA.},
  author-email = {acc@purdue.edu chewanad@purdue.edu abejara@purdue.edu},
  cited-references = {[Anonymous], 2006, NSF WORKSH CHALL SCI. Boyko A., 2009, NDIIPP CONTENT TRANS. Catlin A. C., 2018, P SCI GAT SEP. Catlin AC, 2018, COMPUT SCI ENG, V20, P49, DOI 10.1109/MCSE.2017.3301213. Deelman E, 2018, INT J HIGH PERFORM C, V32, P159, DOI 10.1177/1094342017704893. Frisch M.J., 2016, GAUSSIAN 16 REVISION. Hoehn RD, 2018, FRONT PHYS-LAUSANNE, V6, DOI 10.3389/fphy.2018.00025. King G, 2007, SOCIOL METHOD RES, V36, P173, DOI 10.1177/0049124107306660. Leipzig J, 2017, BRIEF BIOINFORM, V18, P530, DOI 10.1093/bib/bbw020. McLennan M, 2015, CONCURR COMP-PRACT E, V27, P328, DOI 10.1002/cpe.3257. McLennan M, 2010, COMPUT SCI ENG, V12, P48, DOI 10.1109/MCSE.2010.41. Singh M., 1996, P NSF WORKSH WORKFL, P28. Sun XS, 2019, PROG PHOTOVOLTAICS, V27, P55, DOI 10.1002/pip.3043. Weibel A., 1998, 2413 RFC IETF. Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18.},
  da = {2021-06-24},
  doc-delivery-number = {IF6IJ},
  eissn = {1558-366X},
  funding-acknowledgement = {NSF CIF21 DIBBs award [1724728]},
  funding-text = {DEEDS is funded by NSF CIF21 DIBBs award \#1724728. We thank NSF program director A. Walton; co-PIs A. Alam, J. Francisco, M. Sepulveda, and C. Weaver; science domain Postdoctoral Researchers and Graduate students led by T. Patel, R. Asadpour, X. Sun, M. Iacchetta, R. Flynn, R. Hoehn, J. Hodges, and J. Monical; and members of R\&D with major contributions: S. Clark, G. Wickramaarachchi, S. Fernando, and P. Desigavinayagam.},
  journal = {COMPUTING IN SCIENCE \& ENGINEERING},
  journal-iso = {Comput. Sci. Eng.},
  keywords-plus = {HUBZERO; SCIENCE},
  language = {English},
  number = {4},
  number-of-cited-references = {15},
  research-areas = {Computer Science},
  times-cited = {4},
  type = {Article},
  unique-id = {ISI:000473184100005},
  usage-count-last-180-days = {0},
  usage-count-since-2013 = {6},
  web-of-science-categories = {Computer Science, Interdisciplinary Applications}
}

@article{ISI:000537465000018,
  title = {Computational Reproducibility in the Wildlife Society's Flagship Journals},
  author = {Archmiller, Althea A. and Johnson, Andrew D. and Nolan, Jane and Edwards, Margaret and Elliott, Lisa H. and Ferguson, Jake M. and Iannarilli, Fabiola and Velez, Juliana and Vitense, Kelsey and Johnson, Douglas H. and Fieberg, John},
  year = {2020},
  month = jul,
  volume = {84},
  pages = {1012--1017},
  publisher = {{WILEY}},
  address = {{111 RIVER ST, HOBOKEN 07030-5774, NJ USA}},
  issn = {0022-541X},
  doi = {10/gg66q7},
  abstract = {Scientific progress depends upon the accumulation of empirical knowledge via reproducible methodology. Although reproducibility is a main tenet of the scientific method, recent studies have highlighted widespread failures in adherence to this ideal. The goal of this study was to gauge the level of computational reproducibility, or the ability to obtain the same results using the same data and analytic methods as in the original publication, in the field of wildlife science. We randomly selected 80 papers published in the Journal of Wildlife Management and Wildlife Society Bulletin between 1 June 2016 and 1 June 2018. Of those that were suitable for reproducibility review (n = 74), we attempted to obtain study data from online repositories or directly from authors. Forty-two authors did not respond to our requests, and we were further unable to obtain data from authors of 13 other studies. Of the 19 studies for which we were able to obtain data and complete our analysis, we judged that 13 were mostly or fully reproducible. We conclude that the studies with publicly available data or data shared upon request were largely reproducible, but we remain concerned about the difficulty in obtaining data from recently published papers. We recommend increased data-sharing, data organization and documentation, communication, and training to advance computational reproducibility in the wildlife sciences. (c) 2020 The Authors. The Journal of Wildlife Management published by Wiley Periodicals, Inc. on behalf of The Wildlife Society.},
  affiliation = {Archmiller, AA (Corresponding Author), Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Archmiller, Althea A.; Johnson, Andrew D., Concordia Coll, Biol Dept, 901 8th St S, Moorhead, MN 56562 USA. Nolan, Jane, Concordia Coll, 901 8th St S, Moorhead, MN 56562 USA. Edwards, Margaret; Elliott, Lisa H.; Iannarilli, Fabiola; Velez, Juliana; Vitense, Kelsey; Johnson, Douglas H.; Fieberg, John, Univ Minnesota, Dept Fisheries Wildlife \& Conservat Biol, 2003 Upper Buford Circle,Suite 135, St Paul, MN 55108 USA. Ferguson, Jake M., Univ Hawaii Manoa, Dept Biol, 2538 McCarthy Mall, Honolulu, HI 96822 USA.},
  author-email = {althea.archmiller@gmail.com},
  da = {2021-01-10},
  doc-delivery-number = {LU0PD},
  eissn = {1937-2817},
  file = {/Users/awwillc/Zotero/storage/2HYBZ9WY/Archmiller et al. - 2020 - Computational reproducibility in the wildlife soci.pdf},
  journal = {JOURNAL OF WILDLIFE MANAGEMENT},
  journal-iso = {J. Wildl. Manage.},
  keywords = {data sharing; meta-analysis; open science; reproducibility; research methods; statistical methods},
  keywords-plus = {ECOINFORMATICS},
  language = {English},
  number = {5},
  number-of-cited-references = {32},
  oa = {Other Gold},
  orcid-numbers = {Velez, Juliana/0000-0003-0412-2761 Iannarilli, Fabiola/0000-0002-7018-3557 Nolan, Jane/0000-0001-7023-5217 Archer, Althea/0000-0003-1927-0783},
  research-areas = {Environmental Sciences \& Ecology; Zoology},
  researcherid-numbers = {Archer, Althea/AAV-9801-2020},
  times-cited = {1},
  type = {Article},
  unique-id = {ISI:000537465000018},
  usage-count-last-180-days = {2},
  usage-count-since-2013 = {3},
  web-of-science-categories = {Ecology; Zoology}
}

@article{ISI:000641472100002,
  title = {Epistemic Issues in Computational Reproducibility: Software as the Elephant in the Room},
  author = {Hocquet, Alexandre and Wieber, Frederic},
  year = {2021},
  month = jun,
  volume = {11},
  publisher = {{SPRINGER}},
  address = {{VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS}},
  issn = {1879-4912},
  doi = {10/gkm94m},
  abstract = {Computational reproducibility (i.e. issues of reproducibility stemming from the computer as a scientific tool) possesses its own dynamics and narratives of crisis. Alongside the difficulties of computing as an ubiquitous yet complex scientific activity, computational reproducibility suffers from a naive expectancy of total reproducibility and a moral imperative to embrace the principles of free software as a non-negotiable epistemic virtue. We argue that the epistemic issues at stake in actual practices of computational reproducibility are best unveiled by focusing on software as a pivotal concept, one that is surprisingly often overlooked in accounts of reproducibility issues. Software is not only about designing and coding but also about maintaining, supporting, distributing, licensing, and governance; it is not only about developers but also about users. We focus on openness debates among computational chemists involved in molecular modeling software packages as empirical grounding for our argument. We then identify and analyse four epistemic characteristics (transparency, consistency, sustainability and inclusivity) as key to the role of software in computational reproducibility.},
  affiliation = {Hocquet, A (Corresponding Author), CNRS, UMR 7117, Arch Poincare, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, A (Corresponding Author), Univ Lorraine, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, Alexandre; Wieber, Frederic, CNRS, UMR 7117, Arch Poincare, 91 Ave Liberat, F-54001 Nancy, France. Hocquet, Alexandre; Wieber, Frederic, Univ Lorraine, 91 Ave Liberat, F-54001 Nancy, France.},
  article-number = {38},
  author-email = {alexandre.hocquet@univ-lorraine.fr},
  cited-references = {AlNoamany Y, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.163. Atmanspacher H., 2016, REPRODUCIBILITY PRIN, DOI [10.1002/9781118865064, DOI 10.1002/9781118865064]. Baker M, 2016, NATURE, V533, P452, DOI 10.1038/533452a. Benureau FCY, 2018, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00069. Chue Hong, 2015, SOFTWARE SUSTAINABIL. Ensmenger NL., 2010, COMPUTER BOYS TAKE C, DOI [10.7551/mitpress/9780262050937.001.0001, DOI 10.7551/MITPRESS/9780262050937.001.0001]. Geiger S., 2019, 4S ANN M. Gelfert Axel., 2011, MODELS SIMULATIONS R, P145. Gezelter JD, 2015, J PHYS CHEM LETT, V6, P1168, DOI 10.1021/acs.jpclett.5b00285. Hatton L, 2019, IEEE SOFTWARE, V36, P137, DOI 10.1109/MS.2018.2883805. Hey T, 2015, NAT PHYS, V11, P367, DOI 10.1038/nphys3313. Hinsen K, 2019, NATURE, V574, P634, DOI 10.1038/d41586-019-03296-8. Hinsen Konrad, 2014, F1000Res, V3, P101, DOI 10.12688/f1000research.3978.1. Hocquet A, 2017, IEEE ANN HIST COMPUT, V39, P40, DOI 10.1109/MAHC.2018.1221048. Horner J., 2014, PHILOS TECHNOLOGY, V27, P491, DOI [10.1007/s13347-014-0172-9, DOI 10.1007/S13347-014-0172-9]. Humphreys P., 2004, EXTENDING OURSELVES, DOI [10.1093/0195158709.001.0001, DOI 10.1093/0195158709.001.0001]. Jacob CR, 2016, J PHYS CHEM LETT, V7, P351, DOI 10.1021/acs.jpclett.5b02609. Kelty C, 2008, 2 BITS CULTURAL SIGN, DOI [10.1215/9780822389002, DOI 10.1215/9780822389002]. Krylov AI, 2015, J PHYS CHEM LETT, V6, P2751, DOI 10.1021/acs.jpclett.5b01258. Le Onelli S, 2018, RES HIST ECON THOUGH, V36, P129, DOI 10.1108/S0743-41542018000036B009. Lejaeghere K, 2016, SCIENCE, V351, DOI 10.1126/science.aad3000. Lenhard J, 2019, MIND MACH, V29, P19, DOI 10.1007/s11023-019-09492-9. Mahoney MS, 2008, IEEE ANN HIST COMPUT, V30, P8, DOI 10.1109/MAHC.2008.55. Miletic V, 2015, WHAT IS PRICE OPEN S. Neupane JB, 2019, ORG LETT, V21, P8449, DOI 10.1021/acs.orglett.9b03216. Peng RD, 2011, SCIENCE, V334, P1226, DOI 10.1126/science.1213847. Reinhardt C., 2001, CHEM SCI 20 CENTURY. Reinhardt C, 2006, ISIS, V97, P205, DOI 10.1086/504732. Schappals M, 2017, J CHEM THEORY COMPUT, V13, P4270, DOI 10.1021/acs.jctc.7b00489. Spencer Matt, 2015, Perspectives on Science, V23, P466, DOI 10.1162/POSC\_a\_00184. Stodden V, 2016, SCIENCE, V354, P1240, DOI 10.1126/science.aah6168. Symons J, 2019, MIND MACH, V29, P37, DOI 10.1007/s11023-018-9487-0. Wieber Frederic, 2020, Perspectives on Science, V28, P610, DOI 10.1162/posc\_a\_00352. Winsberg E., 2010, SCI AGE COMPUTER SIM, DOI [10.7208/chicago/9780226902050.001.0001, DOI 10.7208/CHICAGO/9780226902050.001.0001]. Winsberg E, 2019, STANFORD ENCY PHILOS.},
  da = {2021-06-23},
  doc-delivery-number = {RP1CB},
  eissn = {1879-4920},
  funding-acknowledgement = {Science History Institute (Philadelphia); MSH Lorraine, France},
  funding-text = {The authors gratefully acknowledge the Science History Institute (Philadelphia) for a fellowship during which some of this research had been pursued. This research project is being supported by a grant from the MSH Lorraine, France.},
  journal = {EUROPEAN JOURNAL FOR PHILOSOPHY OF SCIENCE},
  journal-iso = {Eur. J. Philos. Sci.},
  keywords = {Computational reproducibility; Software; Computational chemistry; Transparency; Consistency; Sustainability; Inclusivity},
  keywords-plus = {SCIENCE; MODELS},
  language = {English},
  number = {2},
  number-of-cited-references = {35},
  orcid-numbers = {Hocquet, Alexandre/0000-0001-6361-5780},
  research-areas = {History \& Philosophy of Science},
  researcherid-numbers = {Hocquet, Alexandre/G-1940-2013},
  times-cited = {0},
  type = {Article},
  unique-id = {ISI:000641472100002},
  usage-count-last-180-days = {4},
  usage-count-since-2013 = {4},
  web-of-science-categories = {History \& Philosophy Of Science}
}

@article{koehlerlemanBetterTogetherElements2020,
  title = {Better Together: {{Elements}} of Successful Scientific Software Development in a  Distributed Collaborative Community.},
  author = {Koehler Leman, Julia and Weitzner, Brian D. and Renfrew, P. Douglas and Lewis, Steven M. and Moretti, Rocco and Watkins, Andrew M. and Mulligan, Vikram Khipple and Lyskov, Sergey and {Adolf-Bryfogle}, Jared and Labonte, Jason W. and Krys, Justyna and Bystroff, Christopher and Schief, William and Gront, Dominik and {Schueler-Furman}, Ora and Baker, David and Bradley, Philip and Dunbrack, Roland and Kortemme, Tanja and {Leaver-Fay}, Andrew and Strauss, Charlie E. M. and Meiler, Jens and Kuhlman, Brian and Gray, Jeffrey J. and Bonneau, Richard},
  year = {2020},
  month = may,
  volume = {16},
  pages = {e1007507},
  issn = {1553-7358 1553-734X 1553-734X},
  doi = {10/ggt62r},
  abstract = {Many scientific disciplines rely on computational methods for data analysis, model  generation, and prediction. Implementing these methods is often accomplished by  researchers with domain expertise but without formal training in software  engineering or computer science. This arrangement has led to underappreciation of  sustainability and maintainability of scientific software tools developed in  academic environments. Some software tools have avoided this fate, including the  scientific library Rosetta. We use this software and its community as a case study  to show how modern software development can be accomplished successfully,  irrespective of subject area. Rosetta is one of the largest software suites for  macromolecular modeling, with 3.1 million lines of code and many state-of-the-art  applications. Since the mid 1990s, the software has been developed collaboratively  by the RosettaCommons, a community of academics from over 60 institutions worldwide  with diverse backgrounds including chemistry, biology, physiology, physics,  engineering, mathematics, and computer science. Developing this software suite has  provided us with more than two decades of experience in how to effectively develop  advanced scientific software in a global community with hundreds of contributors.  Here we illustrate the functioning of this development community by addressing  technical aspects (like version control, testing, and maintenance),  community-building strategies, diversity efforts, software dissemination, and user  support. We demonstrate how modern computational research can thrive in a  distributed collaborative community. The practices described here are independent of  subject area and can be readily adopted by other software development communities.},
  annotation = {QID: Q94512363},
  file = {/Users/awwillc/Zotero/storage/CD4MKHFZ/Koehler Leman et al. - 2020 - Better together Elements of successful scientific.pdf},
  journal = {PLoS computational biology},
  keywords = {Computational Biology/*methods,Cooperative Behavior,Data Analysis,Engineering,Gene Library,Humans,Models; Molecular,Research Personnel,Research/*trends,Social Behavior,Software/*trends,User-Computer Interface},
  language = {eng},
  number = {5},
  pmcid = {PMC7197760},
  pmid = {32365137}
}

@article{leipzigRoleMetadataReproducible2020,
  title = {The Role of Metadata in Reproducible Computational Research},
  author = {Leipzig, Jeremy and N{\"u}st, Daniel and Hoyt, Charles Tapley and {Soiland-Reyes}, Stian and Ram, Karthik and Greenberg, Jane},
  year = {2020},
  abstract = {Reproducible computational research (RCR) is the keystone of the scientific method for in silico analyses, packaging the transformation of raw data to published results. In addition to its role in research integrity, RCR has the capacity to significantly accelerate evaluation and reuse. This potential and wide-support for the FAIR principles have motivated interest in metadata standards supporting RCR. Metadata provides context and provenance to raw data and methods and is essential to both discovery and validation. Despite this shared connection with scientific data, few studies have explicitly described the relationship between metadata and RCR. This article employs a functional content analysis to identify metadata standards that support RCR functions across an analytic stack consisting of input data, tools, notebooks, pipelines, and publications. Our article provides background context, explores gaps, and discovers component trends of embeddedness and methodology weight from which we derive recommendations for future work.},
  file = {/Users/awwillc/Zotero/storage/RBUUZ6SU/Leipzig et al. - 2020 - The role of metadata in reproducible computational.pdf},
  keywords = {⛔ No DOI found,Computer Science - Digital Libraries,Computer Science - Software Engineering}
}

@article{maer-mateiSkillNeedsEarly2019,
  title = {Skill {{Needs}} for {{Early Career Researchers}}\textemdash{{A Text Mining Approach}}},
  author = {{Maer-Matei}, Monica Mihaela and Georgescu, Tiberiu Marian and Mocanu, Cristina and Zamfir, Ana-Maria},
  year = {2019/01/01////},
  volume = {11},
  issn = {20711050},
  doi = {10/ghkb9m},
  abstract = {Research and development activities are one of the main drivers for progress, economic growth and wellbeing in many societies. This article proposes a text mining approach applied to a large amount of data extracted from job vacancies advertisements, aiming to shed light on the main skills and demands that characterize first stage research positions in Europe. Results show that data handling and processing skills are essential for early career researchers, irrespective of their research field. Also, as many analyzed first stage research positions are connected to universities, they include teaching activities to a great extent. Management of time, risks, projects, and resources plays an important part in the job requirements included in the analyzed advertisements. Such information is relevant not only for early career researchers who perform job selection taking into account the match of possessed skills with the required ones, but also for educational institutions that are responsible for skills development of the future R\&D professionals.},
  journal = {Sustainability},
  keywords = {advertising,economic development,employment opportunities,Europe,professionals,research and development,risk management,time management,universities},
  language = {English},
  number = {10}
}

@article{obelsAnalysisOpenData2020,
  title = {Analysis of {{Open Data}} and {{Computational Reproducibility}} in {{Registered Reports}} in {{Psychology}}},
  author = {Obels, Pepijn and Lakens, Dani{\"e}l and Coles, Nicholas and Gottfried, Jaroslav and Green, Seth},
  year = {2020},
  month = may,
  volume = {3},
  pages = {251524592091887},
  doi = {10/gg4vw4},
  abstract = {Ongoing technological developments have made it easier than ever before for scientists to share their data, materials, and analysis code. Sharing data and analysis code makes it easier for other researchers to reuse or check published research. However, these benefits will emerge only if researchers can reproduce the analyses reported in published articles and if data are annotated well enough so that it is clear what all variable and value labels mean. Because most researchers are not trained in computational reproducibility, it is important to evaluate current practices to identify those that can be improved. We examined data and code sharing for Registered Reports published in the psychological literature from 2014 to 2018 and attempted to independently computationally reproduce the main results in each article. Of the 62 articles that met our inclusion criteria, 41 had data available, and 37 had analysis scripts available. Both data and code for 36 of the articles were shared. We could run the scripts for 31 analyses, and we reproduced the main results for 21 articles. Although the percentage of articles for which both data and code were shared (36 out of 62, or 58\%) and the percentage of articles for which main results could be computationally reproduced (21 out of 36, or 58\%) were relatively high compared with the percentages found in other studies, there is clear room for improvement. We provide practical recommendations based on our observations and cite examples of good research practices in the studies whose main results we reproduced.},
  file = {/Users/awwillc/Zotero/storage/H84XYKXR/Obels et al. - 2020 - Analysis of Open Data and Computational Reproducib.pdf},
  journal = {Advances in Methods and Practices in Psychological Science}
}

@techreport{peikertReproducibleDataAnalysis2019,
  title = {A {{Reproducible Data Analysis Workflow}} with {{R Markdown}}, {{Git}}, {{Make}}, and {{Docker}}},
  author = {Peikert, Aaron and Brandmaier, Andreas Markus},
  year = {2019},
  month = nov,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/8xzqy},
  abstract = {In this tutorial, we describe a workflow to ensure long-term reproducibility of R-based data analyses. The workflow leverages established tools and practices from software engineering. It combines the benefits of various open-source software tools including R Markdown, Git, Make, and Docker, whose interplay ensures seamless integration of version management, dynamic report generation conforming to various journal styles, and full cross-platform and long-term computational reproducibility. The workflow ensures meeting the primary goals that 1) the reporting of statistical results is consistent with the actual statistical results (dynamic report generation), 2) the analysis exactly reproduces at a later point in time even if the computing platform or software is changed (computational reproducibility), and 3) changes at any time (during development and post-publication) are tracked, tagged, and documented while earlier versions of both data and code remain accessible. While the research community increasingly recognizes dynamic document generation and version management as tools to ensure reproducibility, we demonstrate with practical examples that these alone are not sufficient to ensure long-term computational reproducibility. Combining containerization, dependence management, version management, and dynamic document generation, the proposed workflow increases scientific productivity by facilitating later reproducibility and reuse of code and data.},
  file = {/Users/awwillc/Zotero/storage/B9BWLKYX/Peikert and Brandmaier - 2019 - A Reproducible Data Analysis Workflow with R Markd.pdf},
  keywords = {containerization,dependency management,literate programming,Meta-science,open science,Quantitative Methods,R,reproducibility,Social and Behavioral Sciences,Statistical Methods,Theory and Philosophy of Science,version management}
}

@article{whiteDevelopingAutomatedIterative2019,
  title = {Developing an Automated Iterative Near-Term Forecasting System for an Ecological Study},
  author = {White, Ethan P. and Yenni, Glenda M. and Taylor, Shawn D. and Christensen, Erica M. and Bledsoe, Ellen K. and Simonis, Juniper L. and Ernest, S. K. Morgan},
  year = {2019},
  volume = {10},
  pages = {332--344},
  issn = {2041-210X},
  doi = {10/gfknh6},
  abstract = {Most forecasts for the future state of ecological systems are conducted once and never updated or assessed. As a result, many available ecological forecasts are not based on the most up-to-date data, and the scientific progress of ecological forecasting models is slowed by a lack of feedback on how well the forecasts perform. Iterative near-term ecological forecasting involves repeated daily to annual scale forecasts of an ecological system as new data becomes available and regular assessment of the resulting forecasts. We demonstrate how automated iterative near-term forecasting systems for ecology can be constructed by building one to conduct monthly forecasts of rodent abundances at the Portal Project, a long-term study with over 40 years of monthly data. This system automates most aspects of the six stages of converting raw data into new forecasts: data collection, data sharing, data manipulation, modelling and forecasting, archiving, and presentation of the forecasts. The forecasting system uses R code for working with data, fitting models, making forecasts, and archiving and presenting these forecasts. The resulting pipeline is automated using continuous integration (a software development tool) to run the entire pipeline once a week. The cyberinfrastructure is designed for long-term maintainability and to allow the easy addition of new models. Constructing this forecasting system required a team with expertise ranging from field site experience to software development. Automated near-term iterative forecasting systems will allow the science of ecological forecasting to advance more rapidly and provide the most up-to-date forecasts possible for conservation and management. These forecasting systems will also accelerate basic science by allowing new models of natural systems to be quickly implemented and compared to existing models. Using existing technology, and teams with diverse skill sets, it is possible for ecologists to build automated forecasting systems and use them to advance our understanding of natural systems.},
  annotation = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13104},
  copyright = {\textcopyright{} 2018 The Authors. Methods in Ecology and Evolution  published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
  file = {/Users/awwillc/Zotero/storage/BPJRE4P2/White et al. - 2019 - Developing an automated iterative near-term foreca.pdf;/Users/awwillc/Zotero/storage/KIBVQ5MW/2041-210X.html},
  journal = {Methods in Ecology and Evolution},
  keywords = {forecasting,iterative forecasting,mammals,Portal Project,prediction},
  language = {en},
  number = {3}
}

@article{wittmanGuideToolboxReplicability2020,
  title = {A {{Guide}} and {{Toolbox}} to {{Replicability}} and {{Open Science}} in {{Entomology}}},
  author = {Wittman, Jacob and Aukema, Brian},
  year = {2020},
  month = may,
  volume = {20},
  doi = {10/ghkb9q},
  abstract = {The ability to replicate scientific experiments is a cornerstone of the scientific method. Sharing ideas, workflows, data, and protocols facilitates testing the generalizability of results, increases the speed that science progresses, and enhances quality control of published work. Fields of science such as medicine, the social sciences, and the physical sciences have embraced practices designed to increase replicability. Granting agencies, for example, may require data management plans and journals may require data and code availability statements along with the deposition of data and code in publicly available repositories. While many tools commonly used in replicable workflows such as distributed version control systems (e.g., 'git') or script programming languages for data cleaning and analysis may have a steep learning curve, their adoption can increase individual efficiency and facilitate collaborations both within entomology and across disciplines. The open science movement is developing within the discipline of entomology, but practitioners of these concepts or those desiring to work more collaboratively across disciplines may be unsure where or how to embrace these initiatives. This article is meant to introduce some of the tools entomologists can incorporate into their workflows to increase the replicability and openness of their work. We describe these tools and others, recommend additional resources for learning more about these tools, and discuss the benefits to both individuals and the scientific community and potential drawbacks associated with implementing a replicable workflow.},
  annotation = {QID: Q95645507},
  file = {/Users/awwillc/Zotero/storage/HJP2I34Q/Wittman and Aukema - 2020 - A Guide and Toolbox to Replicability and Open Scie.pdf},
  journal = {Journal of insect science (Online)}
}

@article{yenniDevelopingModernData2019,
  title = {Developing a Modern Data Workflow for Regularly Updated Data.},
  author = {Yenni, Glenda M. and Christensen, Erica M. and Bledsoe, Ellen K. and Supp, Sarah R. and Diaz, Renata M. and White, Ethan P. and Ernest, S. K. Morgan},
  year = {2019},
  month = jan,
  volume = {17},
  pages = {1--12},
  issn = {15449173},
  abstract = {Over the past decade, biology has undergone a data revolution in how researchers collect data and the amount of data being collected. An emerging challenge that has received limited attention in biology is managing, working with, and providing access to data under continual active collection. Regularly updated data present unique challenges in quality assurance and control, data publication, archiving, and reproducibility. We developed a workflow for a long-term ecological study that addresses many of the challenges associated with managing this type of data. We do this by leveraging existing tools to 1) perform quality assurance and control; 2) import, restructure, version, and archive data; 3) rapidly publish new data in ways that ensure appropriate credit to all contributors; and 4) automate most steps in the data pipeline to reduce the time and effort required by researchers. The workflow leverages tools from software development, including version control and continuous integration, to create a modern data management system that automates the pipeline. [ABSTRACT FROM AUTHOR]},
  annotation = {mlzsync1:0057\{"extrafields":\{"publisher":"Public Library of Science"\}\} QID: Q63607824},
  file = {/Users/awwillc/Zotero/storage/KURGI2LQ/Yenni et al. - 2019 - Developing a modern data workflow for regularly up.pdf},
  journal = {PLoS Biology},
  keywords = {⛔ No DOI found,ACQUISITION of data,Archives,Biological data management,Biology and life sciences,Careers in research,Community Page,Computational biology,Computer and information sciences,Data management,Databases,DATABASES,Engineering and technology,Industrial engineering,INDUSTRIAL engineering,Information centers,Information technology,People and places,Population groupings,Professions,Programming languages,Quality control,QUALITY control,Reproducibility,Research and analysis methods,Research assessment,Research facilities,Science and technology workforce,Science policy,Scientists,WORKFLOW},
  number = {1}
}



@Article{Sequeira2021,
author = {Sequeira, Ana M. M. et al.},
title = {A standardisation framework for bio‐logging data to advance ecological research and conservation},
journal = {Methods in Ecology and Evolution},
volume = {12},
number = {6},
pages = {996–1007},
year = {2021},
abstract = {},
location = {},
keywords = {}}
@Article{Murray2021,
author = {Murray, NJ et al.},
title = {Data Freshness in Ecology and Conservation.},
journal = {Trends Ecol Evol},
volume = {36},
number = {6},
pages = {485–487},
year = {2021},
abstract = {Evolving capabilities in environmental data collection, sharing, and processing, are enabling unprecedented use of data from a wide range of sources. Yet data freshness, an important quality dimension associated with the age of data, is a poorly reported aspect of data quality that can lead to additional uncertainty in research findings.},
location = {College of Science and Engineering, James Cook University, Townsville, Queensland 4811, Australia. Electronic address: nicholas.murray@jcu.edu.au. Remote Sensing Research Centre, School of Earth and Environmental Sciences, University of Queensland, Brisbane, Queensland, 4072, Australia; Australian Institute of Marine Science, Townsville, Queensland 4810, Australia. Australian Research Council Centre of Excellence for Coral Reef Studies, James Cook University, Townsville, Queensland 4811, Australia. Centre for Ecosystem Science, School of Biological, Earth and Environmental Sciences, University of New South Wales, New South Wales, Australia.},
keywords = {}}

@Article{Culina:2018dn,
author = {Culina, Antica et al.},
title = {Navigating the unfolding open data landscape in ecology and evolution},
journal = {Nature Ecology & Evolution},
volume = {},
number = {},
pages = {1–7},
year = {2018},
abstract = {Nature Ecology & Evolution, doi:10.1038/s41559-017-0458-2},
location = {},
keywords = {open data; open science; ecology and evolution; data provenance; ontology; reproducibility; metadata; meta-analysis}}
